{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1_7pQVESOLhAKaEWFEoZuAPAFs1s0iSfJ","timestamp":1720569739776}],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMWuXnKMEomomCIqw/R1e2s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np"],"metadata":{"id":"nvhhZlWJ_Fcr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing import image"],"metadata":{"id":"bUvFKcBg_NGv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사전 학습된 모델 : VGG16"],"metadata":{"id":"RNys0GaS3bQP"}},{"cell_type":"code","source":["from google.colab import files\n","\n","# 이미지 업로드\n","uploaded = files.upload()  # 업로드 창에서 이미지 선택\n","img_path = list(uploaded.keys())[0]\n","img = image.load_img(img_path, target_size=(224, 224))\n","\n","# 시각화\n","plt.imshow(img)\n","plt.axis('off')\n","plt.title(\"Input Image\")\n","plt.show()\n","\n","# 이미지 전처리 (VGG16 입력 형태 맞추기)\n","x = image.img_to_array(img)      # (224,224,3)\n","x = np.expand_dims(x, axis=0)    # (1,224,224,3)\n","x = preprocess_input(x)          # 픽셀값을 VGG16 학습 시 입력 스케일로 변환\n","\n","# 사전 학습된 VGG16 모델 불러오기 (ImageNet 가중치 사용)\n","# include_top=True → 1000개 ImageNet 클래스 분류기 포함\n","model = VGG16(weights='imagenet', include_top=True)\n","\n","# 예측\n","preds = model.predict(x)\n","\n","# 예측 결과 디코딩 (Top-5 클래스)\n","labels = decode_predictions(preds, top=5)[0]\n","\n","print(\"Top-5 Predicted Classes:\")\n","for rank, (imagenet_id, label, prob) in enumerate(labels, start=1):\n","    print(f\"{rank}. {label:15s} ({prob*100:.2f}%)\")"],"metadata":{"id":"dPA_ZzNEo1Gf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"Y-9hWCrgo9ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 특징 추출"],"metadata":{"id":"9oty9Y5bm8_S"}},{"cell_type":"code","source":["from tensorflow.keras import models, layers\n","\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n","base_model.trainable = False    # 특징 추출부 고정\n","\n","model = models.Sequential([\n","   base_model,\n","   layers.Flatten(),\n","   layers.Dense(256, activation='relu'),\n","   layers.Dense(3, activation='softmax')\n","])"],"metadata":{"id":"jnGotzVc9pEF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"ZKCuGq_WpzfL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine Tuning (상위 층 일부 재학습)"],"metadata":{"id":"HOu8h8FpnDO3"}},{"cell_type":"code","source":["from tensorflow.keras import models, layers\n","\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n","base_model.trainable = True\n","\n","# 마지막 Conv 2층만 학습, 나머지는 학습 안함\n","for layer in base_model.layers[:-2] :\n","    layer.trainable = False\n","\n","model = models.Sequential([\n","   base_model,\n","   layers.Flatten(),\n","   layers.Dense(256, activation='relu'),\n","   layers.Dense(3, activation='softmax')\n","])"],"metadata":{"id":"7beVpe72nIHT"},"execution_count":null,"outputs":[]}]}