{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-HQFBHHFmzQ"
   },
   "outputs": [],
   "source": [
    "#ipynb 파일들은 구글 Colab에서 실습\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ozrU3wYgBXgm"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\YSB\\OneDrive\\Desktop\\CV_01\\.venv\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: DLL 초기화 루틴을 실행할 수 없습니다.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YSB\\OneDrive\\Desktop\\CV_01\\.venv\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: DLL 초기화 루틴을 실행할 수 없습니다.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 케라스(Keras)는 파이썬으로 작성된 오픈 소스 신경망 라이브러리\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 2017년 구글 텐서플로(Tensorflow)의 코어 라이브러리에 케라스를 포함하기로 결정\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mds\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YSB\\OneDrive\\Desktop\\CV_01\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YSB\\OneDrive\\Desktop\\CV_01\\.venv\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"c:\\Users\\YSB\\OneDrive\\Desktop\\CV_01\\.venv\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: DLL 초기화 루틴을 실행할 수 없습니다.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "# 케라스(Keras)는 파이썬으로 작성된 오픈 소스 신경망 라이브러리\n",
    "# 2017년 구글 텐서플로(Tensorflow)의 코어 라이브러리에 케라스를 포함하기로 결정\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR3L5m7YUgtB"
   },
   "source": [
    "# 데이터 셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_GJHnVT5Mct"
   },
   "source": [
    "## MNIST(Modified National Institute of Standards and Technology) 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FG4pRRdRHH8s"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ds.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8prkOQSVT9C"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfiDPnBZIOUM"
   },
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAX3GMWgs_TX"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('MNIST', fontsize=30)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i].reshape(28, 28), cmap=plt.cm.gray)\n",
    "    plt.xlabel(str(y_train[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zfvrnt7_UaCd"
   },
   "source": [
    "## fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4cirXfPJ0cE"
   },
   "outputs": [],
   "source": [
    "(fx_train, fy_train), (fx_test, fy_test) = ds.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5W5fa-FRVghW"
   },
   "outputs": [],
   "source": [
    "print(fx_train.shape, fy_train.shape, fx_test.shape, fy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ij__8Dz8x_v"
   },
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "print(fx_train[0], fy_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP1S0w5SWpyf"
   },
   "outputs": [],
   "source": [
    "fashion_class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfHcjhHjtElP"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('fashion-MNIST', fontsize=30)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(fx_train[i].reshape(28, 28), cmap=plt.cm.gray)\n",
    "    plt.xlabel(str(fy_train[i]) +'-'+fashion_class_names[fy_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w1h7VswUcCK"
   },
   "source": [
    "## CIFAR(Canadian Institute for Advanced Research)-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1h7cCaVHLT7"
   },
   "outputs": [],
   "source": [
    "(cx_train, cy_train), (cx_test, cy_test) = ds.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdMpIIHxWIrV"
   },
   "outputs": [],
   "source": [
    "print(cx_train.shape, cy_train.shape, cx_test.shape, cy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuHv851QUj9A"
   },
   "outputs": [],
   "source": [
    "print(cx_train[0], cy_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osiO-Y-4Wgv6"
   },
   "outputs": [],
   "source": [
    "cifar10_class_names=['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r9ubgzVtIqI"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('CIFAR-10',fontsize=30)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cx_train[i].reshape(32, 32, 3))\n",
    "    plt.xlabel(str(cy_train[i][0])+'-'+cifar10_class_names[cy_train[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gErgwNZZ5YuK"
   },
   "source": [
    "# 학습데이터로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWvBbR2x5s8z"
   },
   "source": [
    "## 이미지 자체를 그대로 표현\n",
    "\n",
    "\n",
    "*   입력 이미지를 1차원 특징 벡터로, 0~1로 정규화로 표현\n",
    "*   출력 라벨을 one-hot 인코딩 방법으로 표현\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgWIkKJH31eK"
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "#(x_train,y_train),(x_test,y_test) = ds.mnist.load_data()\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0KzTAHzfa6x"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터 정규화\n",
    "x_trainF = x_train.reshape(60000,784)   # 1차원 구조로 변경\n",
    "x_testF = x_test.reshape(10000,784)\n",
    "\n",
    "x_trainF = x_trainF.astype('float32')   # 0~1로 정규화하기 위해 실수형으로 변환\n",
    "x_testF = x_testF.astype('float32')\n",
    "\n",
    "x_trainF /= 255.0                       # 0~1로 정규화\n",
    "x_testF /= 255.0\n",
    "\n",
    "x_trainF.shape, x_testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB28nzFc8GAb"
   },
   "outputs": [],
   "source": [
    "print(x_trainF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzeU4ARMcW5T"
   },
   "outputs": [],
   "source": [
    "y_train10 = tf.keras.utils.to_categorical(y_train,10)   # one-hot 인코딩\n",
    "y_test10 = tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "y_train10.shape, y_test10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvR_E5H8ZGVJ"
   },
   "outputs": [],
   "source": [
    "print(y_train[0], y_train10[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6gA3-ja6ILJ"
   },
   "source": [
    "## 이미지 특징을 계산하여 사용\n",
    "\n",
    "\n",
    "*   예를 들어 HOG는 81차원의 특징을 계산하여 사용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crenRHue3MDv"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "imsize = 28 # size of image (28x28)\n",
    "# HOG parameters:\n",
    "winSize = (imsize, imsize) # 28, 28\n",
    "blockSize = (imsize//2, imsize//2) # 14, 14\n",
    "cellSize = (imsize//2, imsize//2) #14, 14\n",
    "blockStride = (imsize//4, imsize//4) # 7, 7\n",
    "nbins = 9\n",
    "derivAperture = 1\n",
    "winSigma = -1.0\n",
    "histogramNormType = 0\n",
    "L2HysThreshold = 0.2\n",
    "gammaCorrection = 1\n",
    "nlevels = 64\n",
    "signedGradients = True\n",
    "\n",
    "# define the HOG descriptor\n",
    "hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma,\n",
    "                        histogramNormType, L2HysThreshold, gammaCorrection, nlevels, signedGradients)\n",
    "\n",
    "# compute HOG descriptors\n",
    "x_train_hog = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    descriptor = hog.compute(x_train[i]) # compute the HOG features\n",
    "    x_train_hog.append(descriptor) # append it to the train decriptors list\n",
    "\n",
    "x_test_hog = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    descriptor = hog.compute(x_test[i]) # compute the HOG features\n",
    "    x_test_hog.append(descriptor) # append it to the test descriptors list\n",
    "\n",
    "#train_descriptors = np.array(train_descriptors)\n",
    "x_train_hog = np.resize(x_train_hog, (x_train.shape[0], 81))\n",
    "\n",
    "#test_descriptors = np.array(test_descriptors)\n",
    "x_test_hog = np.resize(x_test_hog, (x_test.shape[0], 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJICoTDw8QFU"
   },
   "outputs": [],
   "source": [
    "print(x_train_hog[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sluM2-lw6t5u"
   },
   "outputs": [],
   "source": [
    "y_train10 = tf.keras.utils.to_categorical(y_train,10)   # one-hot 인코딩\n",
    "y_test10 = tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "y_train10.shape, y_test10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwFl72a96zI7"
   },
   "outputs": [],
   "source": [
    "print(y_train[0], y_train10[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5PYsW948cLR"
   },
   "source": [
    "# 데이터 증강"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epXFfwPDTNg-"
   },
   "source": [
    "## 이미지처리 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec_bx1-FOt5a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rotate(img, angle_deg, scale=1.0):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle_deg, scale)\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "def translate(img, tx, ty):\n",
    "    h, w = img.shape[:2]\n",
    "    M = np.float32([[1,0,tx],[0,1,ty]])\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "def flip(img, mode=1):\n",
    "    # mode: 1=좌우, 0=상하, -1=좌우+상하\n",
    "    return cv2.flip(img, mode)\n",
    "\n",
    "def scale_resize(img, fx=1.0, fy=1.0, keep_size=True):\n",
    "    h, w = img.shape[:2]\n",
    "    scaled = cv2.resize(img, (0,0), fx=fx, fy=fy, interpolation=cv2.INTER_LINEAR)\n",
    "    if keep_size:\n",
    "        # 중앙 크롭/패딩으로 원래 크기 유지\n",
    "        nh, nw = scaled.shape[:2]\n",
    "        out = np.zeros_like(img)\n",
    "        if nh >= h and nw >= w:\n",
    "            # 중앙 크롭\n",
    "            ys = (nh - h)//2; xs = (nw - w)//2\n",
    "            out = scaled[ys:ys+h, xs:xs+w].copy()\n",
    "        else:\n",
    "            # 패딩\n",
    "            out[:] = 0\n",
    "            ys = max((h - nh)//2, 0); xs = max((w - nw)//2, 0)\n",
    "            out[ys:ys+nh, xs:xs+nw] = scaled\n",
    "        return out\n",
    "    return scaled\n",
    "\n",
    "def blur(img, k=5):\n",
    "    k = k if k % 2 == 1 else k+1\n",
    "    return cv2.GaussianBlur(img, (k,k), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6revZMyNSlv"
   },
   "outputs": [],
   "source": [
    "cols = 6\n",
    "rows = 1\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "img = cx_train[0]\n",
    "\n",
    "# 원본\n",
    "plt.subplot(rows, cols, 1)\n",
    "plt.imshow(img); plt.title(\"Original\"); plt.axis(\"off\")\n",
    "\n",
    "# 증강 결과\n",
    "plt.subplot(rows, cols, 2)\n",
    "plt.imshow(rotate(img, 20)); plt.title(\"Rotate 20\"); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(rows, cols, 3)\n",
    "plt.imshow(translate(img, 10, 10)); plt.title(\"Translate (10,10)\"); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(rows, cols, 4)\n",
    "plt.imshow(flip(img, 1)); plt.title(\"Flip\"); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(rows, cols, 5)\n",
    "plt.imshow(scale_resize(img, 1.2, 1.2)); plt.title(\"Scale * 1.2\"); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(rows, cols, 6)\n",
    "plt.imshow(blur(img)); plt.title(\"GaussianBlur\"); plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cD_LvhSxTAsp"
   },
   "source": [
    "## Albumentations 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86Oz9EH2SyYS"
   },
   "outputs": [],
   "source": [
    "!pip install -q albumentations==1.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOwUImmCSz1z"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# 데이터 증강 파이프라인 정의\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                      # 좌우 뒤집기\n",
    "    A.VerticalFlip(p=0.2),                        # 상하 뒤집기\n",
    "    A.RandomRotate90(p=0.3),                      # 90도 단위 회전\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=25, p=0.7),   # 이동, 확대/축소, 회전\n",
    "    A.RandomBrightnessContrast(p=0.5),            # 밝기, 대비\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),  # 가우시안 노이즈\n",
    "    A.HueSaturationValue(p=0.4),                  # 색상 변화\n",
    "    A.Blur(blur_limit=3, p=0.3)                   # 블러\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV4XNApfS_c2"
   },
   "outputs": [],
   "source": [
    "img = cx_train[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(7,4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    augmented = transform(image=img)    # 랜덤 데이터 증강을 수행, image는 증강할 이미지\n",
    "    aug_img = augmented['image']        # 증강된 이미지\n",
    "    axes[i].imshow(aug_img)\n",
    "    axes[i].set_title(f\"Aug {i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPm4xzHfXF0vNBx8JcxYfNJ",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
